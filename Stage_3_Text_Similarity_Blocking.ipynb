{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Blocking\n",
    "\n",
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Prepare Tables\n",
    "1. __Load table data from Github__\n",
    "    1. Spoj Data = *table_A*\n",
    "    2. Codechef Data = *table_B*\n",
    "2. __Combine Text Attributes__\n",
    "    1. Concatenate _description_ + _input_ + _output_ text attributes into single _words_ attribute\n",
    "    2. Drop _description_ + _input_ + _output_ text attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_spoj = \"https://raw.githubusercontent.com/KaranTalreja/CS638/master/spoj/json/spoj_blocking.csv?token=AKuoLTvhQla5FVgd-sWedBmZ7C9MitFsks5YLxDGwA%3D%3D\"\n",
    "table_A = pd.read_csv(urlopen(table_spoj)).drop(\"Unnamed: 0\", axis=1)\n",
    "table_A[\"words\"] = table_A[\"description\"].fillna(\"\") + table_A[\"input\"].fillna(\"\") + table_A[\"output\"].fillna(\"\")\n",
    "table_A = table_A.drop([\"description\", \"input\", \"output\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_codechef = \"https://raw.githubusercontent.com/KaranTalreja/CS638/master/codechef/data/codechef_blocking.csv?token=AD_cZbkPhGiqHVai0GuHnKYh2i7k3xIlks5YMLsuwA%3D%3D\"\n",
    "table_B = pd.read_csv(urlopen(table_codechef))\n",
    "table_B[\"words\"] = table_B[\"description\"].fillna(\"\") + table_B[\"input\"].fillna(\"\") + table_B[\"output\"].fillna(\"\")\n",
    "table_B = table_B.drop([\"description\", \"input\", \"output\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize _Words_ Attribute\n",
    "1. __Create function to standardize words attribute__\n",
    "    1. Remove numbers and special symbols\n",
    "    2. Convert all words to lowercase and split by word\n",
    "    3. Remove common english stopwords and individual alphabetical characters\n",
    "    4. Rejoin text into single string\n",
    "2. __Apply *std_words* function to *Table_A* and *Table_B*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "def std_words(df):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", df[\"words\"]) # letters only, drop numbers & symbols\n",
    "    words = letters_only.lower().split() # lower case, split by word                  \n",
    "    stops = set((nltk.corpus.stopwords.words(\"english\") + \n",
    "                ['a','b','c','d','e','f','g','h','i','j','k','l','m','n',\n",
    "                'o','p','q','r','s','t','u','v','w','x','y','z'])) # general stopwords & letters  \n",
    "    st = LancasterStemmer()\n",
    "    meaningful_words = [st.stem(w) for w in words if not w in stops] # remove stopwords\n",
    "    return( \" \".join( meaningful_words )) # return re-joined string\n",
    "\n",
    "# Step 2\n",
    "table_A[\"words\"] = table_A.apply(std_words, axis=1)\n",
    "table_B[\"words\"] = table_B.apply(std_words, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & Apply Bag of Words\n",
    "1. __Create bag of words from *Table_A*__\n",
    "    1. Maximum 1000 words\n",
    "    2. Each word can be in at most 60% of the instances\n",
    "        1. This is an attempt to prevent using overly common words to block\n",
    "    3. Simply specify if word occurs in a particular instance, do not track the frequency of occurance\n",
    "2. __Fit Vectorizer to *Table_A* the apply to both tables__\n",
    "    1. Must transform the output to an numpy array\n",
    "3. __Map words to a pandas table for both *Table_A* and *Table_B*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             max_features = 1000,\n",
    "                             max_df = 0.6) \n",
    "\n",
    "# Step 2\n",
    "fit_words = vectorizer.fit(table_A[\"words\"])\n",
    "table_A_features = fit_words.transform(table_A[\"words\"]).toarray()\n",
    "table_B_features = fit_words.transform(table_B[\"words\"]).toarray()\n",
    "\n",
    "# Step 3\n",
    "vocab = fit_words.get_feature_names() # words used from corpus\n",
    "word_mapping_A = pd.DataFrame(table_A_features, columns=vocab) # which instances contain each vocab word\n",
    "word_mapping_B = pd.DataFrame(table_B_features, columns=vocab) # which instances contain each vocab word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Blocking on Text\n",
    "1. **Map Table_A to inverse index dictionary**\n",
    "2. **Map Table_B to inverse index dictionary**\n",
    "3. **Start Blocking on string similarities**\n",
    "    1. Use basic similarity measure (percentage of overlap, tokenized by word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "inverse_indexing_A = defaultdict(list)\n",
    "for index, row in word_mapping_A.iterrows():\n",
    "    words = row[row.values >= 1]\n",
    "    for word in words.index:\n",
    "        inverse_indexing_A[word].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "inverse_indexing_B = defaultdict(list)\n",
    "for index, row in word_mapping_B.iterrows():\n",
    "    words = row[row.values >= 1]\n",
    "    for word in words.index:\n",
    "        inverse_indexing_B[word].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% completed.\n",
      "10% completed.\n",
      "20% completed.\n",
      "30% completed.\n",
      "40% completed.\n",
      "50% completed.\n",
      "60% completed.\n",
      "70% completed.\n",
      "80% completed.\n",
      "90% completed.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "def blocking_match(row, min_sim=0.5):\n",
    "    list_of_sim = defaultdict(float)\n",
    "    words = word_mapping_A.ix[row][word_mapping_A.ix[row].values > 0].index\n",
    "    for i in words:\n",
    "        for j in inverse_indexing_B[i]:\n",
    "            list_of_sim[j] = list_of_sim[j] + (1. / len(words))\n",
    "    try:\n",
    "        del list_of_sim[row]\n",
    "    except:\n",
    "        pass\n",
    "    for key in list_of_sim.keys():\n",
    "        if list_of_sim[key] < min_sim:\n",
    "            del list_of_sim[key]\n",
    "    return list_of_sim\n",
    "\n",
    "# Block Rows\n",
    "blocked = defaultdict(list)\n",
    "for row in range(0,len(word_mapping_A)):\n",
    "    blocked[row] = (blocking_match(row, 0.4).keys())\n",
    "    if float(row) % round((len(word_mapping_A)/10.)) == 0:\n",
    "        print \"%.0f%% completed.\" % (100 * float(row) / float((len(word_mapping_A))))\n",
    "    elif float(row) == len(word_mapping_A)-1:\n",
    "        print \"Finished!\"\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format as a Table\n",
    "1. __Columns:__\n",
    "    1. __Table_A_ID:__ Index from table_A (spoj)\n",
    "    2. __Table_B_ID:__ Index from table_B (codechef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% completed.\n",
      "10% completed.\n",
      "20% completed.\n",
      "30% completed.\n",
      "40% completed.\n",
      "50% completed.\n",
      "60% completed.\n",
      "70% completed.\n",
      "80% completed.\n",
      "90% completed.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "compare = pd.DataFrame(columns=[\"table_A_ID\", \"table_B_ID\"])\n",
    "\n",
    "count = 0\n",
    "for key, value in blocked.iteritems():\n",
    "    if float(count) % round((len(blocked)/10.)) == 0:\n",
    "        print \"%.0f%% completed.\" % (100 * float(count) / float((len(blocked))))\n",
    "    elif float(count) == len(blocked)-1:\n",
    "        print \"Finished!\"\n",
    "    else:\n",
    "        pass\n",
    "    count = count + 1\n",
    "    for index in value:\n",
    "        compare = compare.append([{\"table_A_ID\": key, \"table_B_ID\": index}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_A_ID</th>\n",
       "      <th>table_B_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153899</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153900</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153901</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4802.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153902</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153903</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153904</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153905</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153906</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153907</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153908</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>4999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153909</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153910</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153911</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153912</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153913</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153914</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153915</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153916</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153917</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153918</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153919</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153920</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153921</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153922</th>\n",
       "      <td>5162.0</td>\n",
       "      <td>5360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153923</th>\n",
       "      <td>5163.0</td>\n",
       "      <td>4648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153924</th>\n",
       "      <td>5163.0</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153925</th>\n",
       "      <td>5163.0</td>\n",
       "      <td>4900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153926</th>\n",
       "      <td>5164.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153927</th>\n",
       "      <td>5165.0</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153928</th>\n",
       "      <td>5165.0</td>\n",
       "      <td>5335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153929 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        table_A_ID  table_B_ID\n",
       "0              0.0      4261.0\n",
       "1              0.0      4532.0\n",
       "2              0.0      4767.0\n",
       "3              0.0      4942.0\n",
       "4              0.0      5166.0\n",
       "5              0.0      5362.0\n",
       "6              1.0      5335.0\n",
       "7              2.0      5335.0\n",
       "8              3.0      1582.0\n",
       "9              3.0      4767.0\n",
       "10             3.0      5335.0\n",
       "11             4.0      5335.0\n",
       "12             5.0       501.0\n",
       "13             5.0       717.0\n",
       "14             5.0      1446.0\n",
       "15             5.0      1622.0\n",
       "16             5.0      1691.0\n",
       "17             5.0      2670.0\n",
       "18             5.0      3612.0\n",
       "19             5.0      3992.0\n",
       "20             5.0      4087.0\n",
       "21             5.0      4461.0\n",
       "22             5.0      4524.0\n",
       "23             5.0      4595.0\n",
       "24             5.0      4614.0\n",
       "25             5.0      4633.0\n",
       "26             5.0      4648.0\n",
       "27             5.0      4767.0\n",
       "28             5.0      4853.0\n",
       "29             5.0      4900.0\n",
       "...            ...         ...\n",
       "153899      5162.0      4793.0\n",
       "153900      5162.0      4796.0\n",
       "153901      5162.0      4802.0\n",
       "153902      5162.0      4845.0\n",
       "153903      5162.0      4850.0\n",
       "153904      5162.0      4884.0\n",
       "153905      5162.0      4890.0\n",
       "153906      5162.0      4900.0\n",
       "153907      5162.0      4997.0\n",
       "153908      5162.0      4999.0\n",
       "153909      5162.0      5006.0\n",
       "153910      5162.0      5061.0\n",
       "153911      5162.0      5075.0\n",
       "153912      5162.0      5122.0\n",
       "153913      5162.0      5164.0\n",
       "153914      5162.0      5246.0\n",
       "153915      5162.0      5262.0\n",
       "153916      5162.0      5266.0\n",
       "153917      5162.0      5309.0\n",
       "153918      5162.0      5315.0\n",
       "153919      5162.0      5335.0\n",
       "153920      5162.0      5345.0\n",
       "153921      5162.0      5352.0\n",
       "153922      5162.0      5360.0\n",
       "153923      5163.0      4648.0\n",
       "153924      5163.0      4767.0\n",
       "153925      5163.0      4900.0\n",
       "153926      5164.0      5335.0\n",
       "153927      5165.0      4767.0\n",
       "153928      5165.0      5335.0\n",
       "\n",
       "[153929 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
