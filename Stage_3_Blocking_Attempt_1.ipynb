{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Blocking\n",
    "\n",
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Prepare Tables\n",
    "1. __Load table data from Github__\n",
    "    1. Spoj Data = *table_A*\n",
    "    2. Codechef Data = *table_B*\n",
    "2. __Combine Text Attributes__\n",
    "    1. Concatenate _description_ + _input_ + _output_ text attributes into single _words_ attribute\n",
    "    2. Drop _description_ + _input_ + _output_ text attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_spoj = \"https://raw.githubusercontent.com/KaranTalreja/CS638/master/spoj/json/spoj_blocking.csv?token=AKuoLTvhQla5FVgd-sWedBmZ7C9MitFsks5YLxDGwA%3D%3D\"\n",
    "table_A = pd.read_csv(urlopen(table_spoj)).drop(\"Unnamed: 0\", axis=1)\n",
    "table_A[\"words\"] = table_A[\"description\"].fillna(\"\") + table_A[\"input\"].fillna(\"\") + table_A[\"output\"].fillna(\"\")\n",
    "table_A = table_A.drop([\"description\", \"input\", \"output\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_codechef = \"https://raw.githubusercontent.com/KaranTalreja/CS638/master/codechef/data/codechef_blocking.csv?token=AD_cZbkPhGiqHVai0GuHnKYh2i7k3xIlks5YMLsuwA%3D%3D\"\n",
    "table_B = pd.read_csv(urlopen(table_codechef))\n",
    "table_B[\"words\"] = table_B[\"description\"].fillna(\"\") + table_B[\"input\"].fillna(\"\") + table_B[\"output\"].fillna(\"\")\n",
    "table_B = table_B.drop([\"description\", \"input\", \"output\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index based on solve_rate for both tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverse_indexing_rate_A = defaultdict(list)\n",
    "bins = [x/2.0 for x in range(0,10,2)]\n",
    "for index, value in table_A[\"solve_rate_normalized\"].iteritems():\n",
    "    for upper_bound in bins:\n",
    "        if value < upper_bound:\n",
    "            inverse_indexing_rate_A[upper_bound].append(index)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverse_indexing_rate_B = defaultdict(list)\n",
    "bins = [x/2.0 for x in range(0,10,2)]\n",
    "for index, value in table_B[\"solve_rate_normalized\"].iteritems():\n",
    "    for upper_bound in bins:\n",
    "        if value < upper_bound:\n",
    "            inverse_indexing_rate_B[upper_bound].append(index)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% completed.\n",
      "2016-11-12 17:07:02.756835\n"
     ]
    }
   ],
   "source": [
    "compare_rate = pd.DataFrame(columns=[\"table_A_solve_rate_normalized\", \"table_B_solve_rate_normalized\"])\n",
    "bins = [x/2.0 for x in range(0,20,1)]\n",
    "count = 0\n",
    "for table_A_index,value in table_A[\"solve_rate_normalized\"].iteritems():\n",
    "    if float(count) % round((len(table_A[\"solve_rate_normalized\"])/10.)) == 0:\n",
    "        print \"%.0f%% completed.\" % (100 * float(count) / float((len(table_A[\"solve_rate_normalized\"]))))\n",
    "        print str(datetime.now())\n",
    "    elif float(count) == len(table_A[\"solve_rate_normalized\"])-1:\n",
    "        print \"Finished!\"\n",
    "        print str(datetime.now())\n",
    "    else:\n",
    "        pass\n",
    "    count = count + 1\n",
    "    bound = 0.0\n",
    "    for upper_bound in bins:\n",
    "        if value < upper_bound:\n",
    "            bound = upper_bound\n",
    "            break\n",
    "    for table_B_index in inverse_indexing_rate_B[bound]:\n",
    "        compare_rate = compare_rate.append([{\"table_A_solve_rate_normalized\": table_A_index, \\\n",
    "                                   \"table_B_solve_rate_normalized\": table_B_index}],\\\n",
    "                                 ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the histogram of problems on solve_rate_normalized, there lies a huge amount of problems in the initial intervals. This causes the blocking to not remove many problem candidates from the set. So this feature is dropped from use in blocking, but this could still be used in matching."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
